{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset dutch_social (C:\\Users\\Emiel\\.cache\\huggingface\\datasets\\dutch_social\\dutch_social\\1.1.0\\4ec8e931ab57f4a4483ad4b418676a45a7f6fec1cf6506da7d99c97259f7e02f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b585255a357408ea303ac53fdaf5e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dutch_social\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['full_text', 'text_translation', 'screen_name', 'description', 'desc_translation', 'location', 'weekofyear', 'weekday', 'month', 'year', 'day', 'point_info', 'point', 'latitude', 'longitude', 'altitude', 'province', 'hisco_standard', 'hisco_code', 'industry', 'sentiment_pattern', 'subjective_pattern', 'label'],\n",
       "    num_rows: 54268\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(dataset['test'])\n",
    "train_data = pd.DataFrame(dataset['train'])\n",
    "validation_data = pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>text_translation</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "      <th>desc_translation</th>\n",
       "      <th>location</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>province</th>\n",
       "      <th>hisco_standard</th>\n",
       "      <th>hisco_code</th>\n",
       "      <th>industry</th>\n",
       "      <th>sentiment_pattern</th>\n",
       "      <th>subjective_pattern</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maar , er iets nuttigs mee doen ? Zie jij 'm v...</td>\n",
       "      <td>However, there is something useful to do with ...</td>\n",
       "      <td>RonaldMeeuwis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @daphneskopelos: Door de coronacrisis zijn ...</td>\n",
       "      <td>RT @daphneskopelos: The corona crisis are abou...</td>\n",
       "      <td>IBeugel</td>\n",
       "      <td>Journalist, programmamaker, schrijver, oud Bal...</td>\n",
       "      <td>Journalist, filmmaker, writer, former Balkans ...</td>\n",
       "      <td>Griekenland</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>38.995368</td>\n",
       "      <td>21.987713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Geovation: What role do ethics and locatio...</td>\n",
       "      <td>RT @Geovation: What role do ethics play data a...</td>\n",
       "      <td>hanscees</td>\n",
       "      <td>Systeemdenker, eigenaar https://t.co/5Cgd9GwmW...</td>\n",
       "      <td>Systems Thinker, owner https://t.co/5Cgd9GwmWt...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>52.500170</td>\n",
       "      <td>5.748082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flevoland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @MollyJongFast: Laura Ingraham is going to ...</td>\n",
       "      <td>RT @MollyJongFast: Laura Ingraham is going to ...</td>\n",
       "      <td>LDUniGr</td>\n",
       "      <td>CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...</td>\n",
       "      <td>CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...</td>\n",
       "      <td>Groningen, The Netherlands</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>53.219065</td>\n",
       "      <td>6.568008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Groningen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @kneeyockartee: Corona has robbed me of man...</td>\n",
       "      <td>RT @kneeyockartee: Corona has robbed me of man...</td>\n",
       "      <td>transxlucence</td>\n",
       "      <td>welkom in de chaos van mijn hoofd. geniet van ...</td>\n",
       "      <td>welcome to the chaos of my head. enjoy the con...</td>\n",
       "      <td>amsterdam/utrecht</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>52.094975</td>\n",
       "      <td>5.109708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  Maar , er iets nuttigs mee doen ? Zie jij 'm v...   \n",
       "1  RT @daphneskopelos: Door de coronacrisis zijn ...   \n",
       "2  RT @Geovation: What role do ethics and locatio...   \n",
       "3  RT @MollyJongFast: Laura Ingraham is going to ...   \n",
       "4  RT @kneeyockartee: Corona has robbed me of man...   \n",
       "\n",
       "                                    text_translation    screen_name  \\\n",
       "0  However, there is something useful to do with ...  RonaldMeeuwis   \n",
       "1  RT @daphneskopelos: The corona crisis are abou...        IBeugel   \n",
       "2  RT @Geovation: What role do ethics play data a...       hanscees   \n",
       "3  RT @MollyJongFast: Laura Ingraham is going to ...        LDUniGr   \n",
       "4  RT @kneeyockartee: Corona has robbed me of man...  transxlucence   \n",
       "\n",
       "                                         description  \\\n",
       "0                                               None   \n",
       "1  Journalist, programmamaker, schrijver, oud Bal...   \n",
       "2  Systeemdenker, eigenaar https://t.co/5Cgd9GwmW...   \n",
       "3  CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...   \n",
       "4  welkom in de chaos van mijn hoofd. geniet van ...   \n",
       "\n",
       "                                    desc_translation  \\\n",
       "0                                               None   \n",
       "1  Journalist, filmmaker, writer, former Balkans ...   \n",
       "2  Systems Thinker, owner https://t.co/5Cgd9GwmWt...   \n",
       "3  CSO CarbExplore BV https://t.co/8IoRT28pWm\\nem...   \n",
       "4  welcome to the chaos of my head. enjoy the con...   \n",
       "\n",
       "                     location  weekofyear  weekday  month  year  ...  \\\n",
       "0                        None          21        3      5  2020  ...   \n",
       "1                 Griekenland          23        2      6  2020  ...   \n",
       "2                 Netherlands          18        4      5  2020  ...   \n",
       "3  Groningen, The Netherlands          21        0      5  2020  ...   \n",
       "4           amsterdam/utrecht          37        6      9  2020  ...   \n",
       "\n",
       "    latitude  longitude altitude   province  hisco_standard  hisco_code  \\\n",
       "0   0.000000   0.000000      0.0      False            None        None   \n",
       "1  38.995368  21.987713      0.0      False            None        None   \n",
       "2  52.500170   5.748082      0.0  Flevoland            None        None   \n",
       "3  53.219065   6.568008      0.0  Groningen            None        None   \n",
       "4  52.094975   5.109708      0.0    Utrecht            None        None   \n",
       "\n",
       "  industry sentiment_pattern subjective_pattern  label  \n",
       "0    False               0.0                0.0      1  \n",
       "1    False               0.0                0.0      1  \n",
       "2    False               0.0                0.0      1  \n",
       "3    False               0.0                0.0      1  \n",
       "4    False               0.0                0.0      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6014127764127765\n"
     ]
    }
   ],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features\n",
    "\n",
    "\n",
    "featuresets = [(dialogue_act_features(post), target) for post, target in list(zip(train_data['full_text'],train_data['label']))]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", padding = True)\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}